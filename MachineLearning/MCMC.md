# [MCMC(一)蒙特卡罗方法](https://www.cnblogs.com/pinard/p/6625739.html) 		

#  MCMC 		

MCMC方法想要解决的问题：从一个极端复杂的分布中采样，因为如果能够对该分布进行采样，我们就可以求出该分布的任何指标的期望，用数学的方法来讲的话是这样的：
$$
E_{x \sim p(x)}[f(x)] =  \int f(x)p(x)d(x) = \frac{1}{N} \sum_{i=1}^N f(x_i)
$$
所以我们现在需要采Ｎ个样本$x_1,x_2,...x_N$使得这Ｎ个样本构成的分布是原分布$P(x)$的一个很好的模拟，那么如何保证这一点呢，这里使用的方法叫做马尔科夫链蒙特卡洛（ Markov Chain Monte Carol）．

## 马尔科夫链

**马尔科夫链**是一个著名的随机过程，这个随机过程的最显著的特性是，下一个状态之依赖于当前的状态，而与当前状态之前的状态无关,也就是说这个随机过程具有健忘性．用数学方法来表示就是：
$$
p(x_{t+1}| x_t,x_{t-1},x_{t-2},...x_0 ) = p(x_{t+1}| x_t)
$$
这个特性让马尔科夫链可以作为一个简化的模型，使它能够被更好的研究和应用．上述的转移概率一般是使用状态转移矩阵来表示的，而马尔科夫链的状态转移矩阵有非常好的性质．如果我们定义矩阵P某一位置$P(i,j)$的值为$P(j|i)$ ，也就是从状态$i$转移到状态$j$的概率，这个矩阵Ｐ就被称为状态转移矩阵．

对于一个状态分布$\pi_t$，通过状态转移矩阵$P$进行一次状态转移之后，生成的状态分布$\pi_{t+1}$，这个过程可以表示为$\pi_{t+1}=\pi_{t}P$．尽管每次我们可以采用了不同初始概率分布$\pi_0$，最终状态的概率分布趋于同一个稳定的概率分布$\pi$，这个概率分布被成为该转移矩阵的稳定概率分布，也就是说我们的**马尔科夫链模型的状态转移矩阵收敛到的稳定概率分布与我们的初始状态概率分布无关**。这是一个非常好的性质，也就是说，如果我们得到了这个稳定概率分布对应的马尔科夫链模型的状态转移矩阵，则我们可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，这样经过一些序列的转换，最终就可以得到符合对应稳定概率分布的样本。

马尔科夫链转移矩阵的收敛性总结一下有以下几点：

如果一个非周期的马尔科夫链有状态转移矩阵$P$, 并且它的任何两个状态是连通的，那么$\lim_{n \rightarrow ∞}P^n_{ij}$与$i$无关，我们有：

- $$
  \pi P = \pi
  $$

- $$
  \lim_{n \rightarrow \infty }P^n_{ij} = \pi_j
  $$

- $$
  \pi_j = \sum_{i=1}^\infty \pi_i P_{ij}
  $$

- $\pi$是方程$\pi P = \pi$的唯一非负解，其中$\sum \pi_i =1$，是所有状态的稳定的概率分布．

1. 非周期的马尔科夫链：这个主要是指马尔科夫链的状态转化不是循环的，如果是循环的则永远不会收敛。幸运的是我们遇到的马尔科夫链一般都是非周期性的。
2. 任何两个状态是连通的：这个指的是从任意一个状态可以通过有限步到达其他的任意一个状态，不会出现条件概率一直为0导致不可达的情况。
3. 马尔科夫链的状态数可以是有限的，也可以是无限的。因此可以用于连续概率分布和离散概率分布。
4. **$\pi$通常称为马尔科夫链的平稳分布**。

由于上述的转移矩阵的收敛性质，我们可以通过采样的方法来获得该转移矩阵的平稳分布$\pi$，具体方法就是通过一个随机的初始概率分布和转移矩阵来形成一个马尔科夫链，然后取很多次转移之后的某一个片段即可．因为通过多次转移之后，我们可以假定该分布已经达到了平稳分布．



## 细致平衡条件和转移矩阵

由于上述的马尔科夫链的特性，我们可以有这样的思路，假设我想知道一个概率分布$\pi$，那么如果我能够知道满足$\pi P = \pi$的这个转移矩阵$P$，那么我就可以通过上述对转移矩阵的采样方法，得到它的平稳分布，也就是现在我们想要得到的分布$\pi$．但是这个转移矩阵好求么？答案是不好求．　那么怎样来解决这个问题呢，我们首先研究一下细致平衡条件．

细致平衡条件：如果对于非周期的马尔科夫链的转移矩阵$P$和一个分布$\pi$，对于每一个$i,j$都满足：
$$
\pi_i P_{i,j} = \pi_j P_{ji}
$$
那么我们则称概率分布$\pi$是转移矩阵$P$的平稳分布，为什么可以这么定义呢？
$$
\sum_i \pi_i p_{i,j} = \sum_i \pi_j p_{j,i} = \pi_j
$$
用矩阵的方法来表示就是　$\pi P = \pi$

所以，只要我们找到一个$P$，使得对所有的$i,j$，都满足细致平衡条件，那么我们对这个转移矩阵采样，就可以得到我们想要的平稳分布$\pi$.  但是就算如此，这个转移矩阵还是不好找的，我们通过蒙特卡洛方法来解决这个问题．

### 使用接受拒绝方法寻找转移矩阵

假设我们想从某个分布$\pi$中采样，对于每个$i$我们可以很容易的计算$\pi_i$，这个假设貌似不是很合理，因为如果这样的话，我们还是很容易的可以进行采样的．但是这里我们先按下不表．然后我们生成一个转移矩阵$Q$，这个$Q$并不是最终的转移矩阵，因为它和分布并不满足细致平衡条件，也就是说　$\pi_i Q_{i,j} \neq \pi_j Q_{j,i}$ 那么我们怎样改造它们，使得细致平衡条件成立呢？最简单的方法是在两边乘以一个接受率，将两边配平．$\pi_i Q_{i,j}\alpha_{i,j} =  \pi_j Q_{j,i} \alpha_{j,i}$，　其中　$\alpha_{i,j} = \pi_j Q_{j,i}$ 并且$\alpha_{j,i} = \pi_i Q_{i,j}$．　这样$P_{i,j} = Q_{i,j} \alpha_{i,j}$，　那么就满足了细致平衡条件．在这种情况下，我们如何对某个分布进行采样呢？



input ：　需要采样的分布$\pi$以及相应的转移矩阵$Q$．

1. 随机产生一个初始状态$x_0$

1. 通过转移矩阵$Q(x_{t+1}| x_t)$生成新的状态　$x_{*}$

2. 在均匀分布$[0,1]$中采样获得接受率$\alpha$

3. 如果$\alpha＞\pi_j Q_{j,i}$那么接受该新的状态到状态序列中

4. 反之，不接受该状态

5. 　重复步骤２－５直到采样结束

   

经过一段时间的采样之后，该状态序列$X$所形成的分布，可以作为分布$\pi$的一个模拟．上面这个过程基本上是MCMC采样的完整采样理论了，但是这个采样算法还是比较难在实际中应用，为什么呢？

1. 问题在上面第三步的c步骤，**接受率**这儿。由于$\alpha(x_t,x_∗)$可能非常的小，比如0.1，导致我们大部分的采样值都被拒绝转移，采样效率很低。有可能我们采样了上百万次马尔可夫链还没有收敛，也就是上面这个$n_1$要非常非常的大，这让人难以接受，怎么办呢？这时就轮到我们的M-H采样出场了。
2. 每个状态的概率$\pi_i$并不是很好算，对于一个复杂的分布来说，因为一般来说，如果对于每个状态都能得到概率，那么也基本上知道这个分布本身是什么样子了,根本不需要使用这种采样方式了．

为了解决上述的两个问题，我们有了Metropolis-Hastings采样．



## Metropolis-Hastings 采样

M-H 方法首首先被Metropolis 提出，然后被Hastings 改进，用来解决上述接受率太低的问题．

首先，我们回到上面的等式中：
$$
 \pi_i Q_{i,j}\alpha_{i.j}= \pi_j Q_{j,i}\alpha_{j,i} 
$$
这里的接受率可能都很低，注意到如果我们把两边都乘以一个系数，那么接受率提高了，并且这个等式依然成立．

所以我们取：$\alpha_{i,j} = min(\frac{\pi_j Q_{j,i}}{\pi_i Q_{i,j}},1) $这里使用的情况相当于将$\alpha_{j,i}$取成1．所以，完整的Metropolis-Hastings 的算法是这样的：

input: 采样概率分布$\pi$,  转移矩阵$Q$, 起始采样点索引$n_1$，　采样数目$n_2$

1. 首先从一个随机的采样点开始$x_0$

2. for t from 0 to $n_i+n_2-1$:

     1.通过转移矩阵$Q(x| x_t)$ 生成新的状态$x^*$

   2. 计算可能的接受率$ \alpha = min(\frac{\pi_j Q_{j,i}}{\pi_i Q_{i,j}},1)$
   3. 在$[0,1]$均匀分布中采样得到$mu$
   4. 如果$\mu > \alpha $那么$x_{t+1} = x*$ 否则　$x_{t+1}=x_{t}$

这样得到的序列$[x_{n_1}, x_{n_2}, x_{n_3},....x_{n_1+n_2-1}]$就是我们需要的平稳分布$\pi$采样的样本集．

M-H 采样方法的优点：

1. 不需要目标分布的很多知识，并且不需要知道每个点的真实概率，而只要知道两点之间的概率比值．
2. 接受率比单纯的MCMC更高
3. 这里貌似任何一个$Q$作为转移矩阵都可以，但是我们可以将该转移矩阵定义成我们需要的样子，例如具有一个很简单的形式，或者具有某种特性（对称）．

M-H采样方法的不足之处：

1. 我们的数据特征非常的多，M-H采样由于接受率计算式$\frac{\pi_jQ_{j,i}}{i_iQ_{i,j}}$的存在，在高维时需要的计算时间非常的可观，算法效率很低。同时$\alpha_{i,j}$一般小于1，有时候辛苦计算出来却被拒绝了。能不能做到不拒绝转移呢？
2. 由于**特征维度大**，很多时候我们甚至很难求出目标的各特征维度联合分布，但是可以方便求出各个特征之间的条件概率分布。这时候我们能不能只有各维度之间条件概率分布的情况下方便的采样呢？

## optimization and control 选择合适的转移矩阵并且为采样过程加速

转移矩阵的选择对于算法的收敛至关重要，它决定了M-H sampling算法的表现．

现在比较有前途的方法有两个：

1. 找到一个比较好的对目标概率分布的模拟，然后通过接受拒绝采样来获得比较高的接受率
2. 使用random walk 



## Gibbs Sampling 吉布斯采样

与前面的M-H采样方法很不相同，吉布斯采样每次采样的时候并不将一个高维分布采完，而是分步采样，每次固定其他维度而之对当前维度采样．这种方法可以并行，并且不需要接受率，在高维数据采样中有很多应用．这种性质天然的可以被应用采样中．

![img](https://images2015.cnblogs.com/blog/1042406/201703/1042406-20170330161210195-1389960329.png)



我们可以理解到，Gibbs Sampling 与M-H sampling 其实是各有长处的：

1. M-H sampling 对于目标平稳分布的要求很低，基本上是没有要求的，并且这个算法有很多实现方式，如果选择不同的$Q$的话．但是这个方法在多维数据上的使用会有所限制，收敛会变得很慢(curse of dimensions)．
2. Gibbs sampling 由于对目标概率分布需要一些特定的知识（因为它需要从条件概率分布中采样），所以其实更加有所限制，但是这个方法其实更加有效，并且可以被应用到多维分布．