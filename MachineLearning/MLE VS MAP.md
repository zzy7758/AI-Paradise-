# 极大似然估计和最大后验概率估计的区别

## 极大似然估计(maximum likelihood estimation)

*极大似然估计一种概率论在统计学的应用，它是参数估计的方法之一。说的是已知某个随机样本满足某种概率分布]，但是其中具体的参数不清楚，参数估计就是通过若干次试验，观察其结果，利用结果推出参数的大概值。极大似然估计是建立在这样的思想上：已知某个参数能使这个样本出现的概率最大，我们当然不会再去选择其他小概率的样本，所以干脆就把这个参数作为估计的真实值。*

*更数学的描述:*

*考虑一组含有$m$个样本的数据集 $X = {x_1,x_2,x_3..x_m}$, 独立的由一个真实的数据分布生成$p_{data}(x)$.*

*我们定义一族具有参数$\theta​$确定的的概率分布$p_{model}(x;\theta)​$,这个分布对于任何$x​$的值映射到其对应的概率, 对于不同的参数$\theta​$取值,对应着不同的概率分布.*

*对$\theta​$的极大似然估计被定义为:*
$$
\begin{align*}

\theta_{ML} = &\arg \max_\theta P_{model}(X; \theta) \\ 
                       = & \arg \max_\theta \prod_{i=1}^{m} p_{model}(x_i; \theta)

\end{align*}
$$
*我们观察到似然对数并不会改变其最大值,于是我们将乘积转化成求和的形式:*


$$
\begin{align*}

\theta_{ML} = &\arg \max_\theta  \log P_{model}(X; \theta) \\ 
                       = & \arg \max_\theta \sum_{i=1}^{m} \log p_{model}(x_i; \theta)

\end{align*}
$$
*因为当重新缩放代价函数的时候,得到的最优值不变,我们可以除以$m​$得到和训练数据经验分布$\hat p_{data} ​$想给你的期望作为准则.*
$$
\begin{align*}

\theta_{ML} = &\arg \max_\theta  \log P_{model}(X; \theta) \\ 
                       = & \arg \max_\theta \sum_{i=1}^{m} \log p_{model}(x_i; \theta) \\
                       = &  \arg \max_\theta E_{x \sim \hat{p}_{data} }\log p_{model}(x_i; \theta)

\end{align*}
$$
*一种解释极大似然估计的观点是将它看做最小化训练集上的经验分布$\hat p_{data}​$ 和模型分布之间的差异,两者之间的差异可以通过$KL​$散度来度量, $KL​$ 散度被定义为:*
$$
D_{KL} (\hat p_{data}|| p_{model}) = E_{x \sim \hat p_{data}} [\log \hat p_{data}(x)  - \log  p_{model}(x) ]
$$
*由于第一项只跟数据生成过程有关,和模型无关,所以当训练模型来最小化$KL​$散度的时候,我们只需要最小化*
$$
- E_{x \sim \hat p_{data}}  \log  p_{model}(x)
$$
*,这和上式中的最大化是相同的.*

*我们可以将极大似然看做使模型分布尽可能的和经验分布相匹配的尝试,但是当前的情况下,我们并不能知道模型的真实分布.极大似然估计最吸引人的地方在于,当样本数目足够大的时候,就收敛而言是最好的渐进估计.*



## *贝叶斯统计(极大后验概率估计)*

 贝叶斯统计与频率学派的最大的分歧在于,贝叶斯统计中,并不假设所有参数具有某个真实的不变的值,而是这些参数本身具有一个分布. 例如在前面的例子中,频率学派认为$\theta​$是一个固定值,但是在贝叶斯学派中,这并不成立.

*贝叶斯统计使用概率反应知识状态的不确定性.数据集能够被直观的观测到,所以它们并不是随机的,另一方面,真实参数$\theta​$是未知或者不确定的,因此可以表示成随机变量.*

在观察到数据前,我们将$\theta​$的已知知识表示成先验概率分布(prior probability distribution), $p(\theta)​$. 一般来说,机器学习实践者会选择一个相当宽泛的先验分布,以反映在观测到任何数据之前参数的高度不确定性. 

*现在假设我们有一组数据样本$x_1,x_2,x_3...x_m​$, 通过贝叶斯规则结合数据似然函数 $p(x_1,x_2,...x_m | \theta)​$和先验, 可以恢复数据对我们关于$\theta​$信念的影响:*
$$
P(\theta | x_1,x_2,x_3 ... x_m) = \frac{p(x_1,x_2,...x_m | \theta) p(\theta)}{p(x_1,x_2,x_3 ... x_m)}
$$
*jiashe在贝叶斯估计的常用情境下,先验开始是相对均匀的分布或者高熵的高斯分布,观测数据通常会使后验的熵下降,并集中在参数的可能性很高的值.*

### *贝叶斯估计与极大似然估计的区别*(主要是贝叶斯估计存在先验假设)

1. *贝叶斯估计使用的是参数分布的全分布,而极大似然估计使用的是$\theta$的点估计*
2. 在贝叶斯估计中,由于使用了先验分布,先验分布能够影响概率质量密度朝参数空间中偏好先验的区域偏移.在实践中,先验通常表现为偏好更加简单或者光滑的模型,对贝叶斯方法的批判认为,先验是人为的主观的判断影响预测的来源.
3. 当预测样本数据很有限的时候,一般来说贝叶斯方法通常泛化的更好,但是当训练样本数目很大的时候,通常会有很大的计算代价



## 极大后验概率估计( maximum a posterior)

MAP选择后验概率最大的点:
$$
\theta_{MAP} = \arg \max_\theta p(\theta | x) = \arg \max_\theta \log p(x|\theta) + \log p(\theta)
$$
而极大似然估计选择的是:
$$
\theta_{ML} = \arg \max_\theta \log  p(x; \theta)
$$
从这种角度来看,带有正则化项的极大似然估计,可以被解释为贝叶斯推断的MAP近似.这个适应于正则化时加到目标函数的附加项对应着的$\log p(\theta)$.但是并非所有的惩罚都对应着MAP贝叶斯推断,例如有些正则化项可能不是一个概率分布的对数,或者难以用这种方法来表示,比如这个正则化项依赖于数据本身. 所以从这个点来看,极大后验概率估计比MAP的应用范围更广泛.

但是贝叶斯推断提供了一个直观的方法来设计复杂但是可以解释的正则化.例如更复杂的惩罚项可以通过混合高斯分布作为先验来得到.